
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>部署你的模型 &#8212; MegEngine 1.2.0 文档</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.361b90cc13c3b373e3e2df043d87d1bd.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.4bc14ce28f4cf826ca84.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script src="../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="模型正确性、速度验证与性能调试" href="load-and-run.html" />
    <link rel="prev" title="导出序列化模型" href="dump.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">


    
      
      <a class="navbar-brand" href="../index.html">
        <img src="../_static/logo.png" class="logo" alt="logo">
      </a>
      
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../getting-started/index.html">
  新手入门
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  用户指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../reference/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../developmet/index.html">
  开发者指南
 </a>
</li>

        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discuss.megengine.org.cn/">论坛<i class="fas fa-external-link-alt"></i></a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://megengine.org.cn/">官网<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>


      <form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="输入搜索文本..." aria-label="输入搜索文本..." autocomplete="off" >
</form>
      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/MegEngine/MegEngine" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
        
        <li class="version_switcher nav-item dropdown"><script type="text/javascript">
    (function () {

        // TODO: Handle with api.json file to get the meta-data.

        // Select versions that could be switched by user
        var all_versions = {
            'latest': 'v1.2.0',
            'v1.1': 'v1.1.0',
            'v1.0': 'v1.0.0',
        };

        function change_version(url, new_version) {
            var version_regex = /\/(latest|(v\d+\.\d+.\d+))\//;
            return url.replace(version_regex, '/' + new_version + '/');
        }

        function on_switch() {
            var selected = $(this).children('option:selected').attr('value');

            // original url
            var url = window.location.href;
            // changed url
            var new_url = change_version(url, selected);

            if (new_url != url) {
                // check beforehand if url exists, otherwise redirect to the version's start page
                $.ajax({
                    url: new_url,
                    success: function () {
                        window.location.href = new_url;
                    },
                    error: function () {
                        window.location.href = "https://pydata-sphinx-theme.readthedocs.io/en/" + selected;
                    }
                });
            }
        }

        $(document).ready(function () {
            // var version = DOCUMENTATION_OPTIONS.VERSION;
            // Take the first 2 parts of the release (e.g. "3.4.5" -> "3.4")
            // version = version.split('.').slice(0, 2).join('.');

            // fill the current version in the dropdown
            document.getElementById("version-dropdown").innerText = 'latest';

            const getVersionLink = () => {
                return Object.keys(all_versions).map(key => `<button class="dropdown-item">${key}</button>`)
            }
            // fill the version menu
            document.getElementById("version-menu").innerHTML = getVersionLink().join('');

            // bind the changes to this menu to trigger the switching function
            // TODO: Change this to use the dropdown button's on_select() callback function
            $('.version-dropdown select').bind('change', on_switch);
        });
    })();

</script>

<button id="version-dropdown" class="btn btn-secondary btn-sm dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
    <!-- placeholder for javascript filling above -->
</button>
<div id="version-menu" class="dropdown-menu" style="min-width: 6rem;">
    <!-- placeholder for javascript filling above -->
</div> 
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
      <li class="toctree-l2">
 <a class="reference internal" href="distribution.html">
  分布式训练
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="quantization.html">
  量化训练
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="advanced-parameter-optimization.html">
  参数优化进阶配置
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="trace.html">
  动态图转静态图
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="sublinear-memory.html">
  亚线性内存优化
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="dump.html">
  导出序列化模型
 </a>
</li>

<li class="toctree-l2 current active">
 <a class="current reference internal" href="#">
  部署你的模型
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="load-and-run.html">
  模型正确性、速度验证与性能调试
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="codegen.html">
  使用 codegen 减少访存操作
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="midout.html">
  使用 midout 进行端上裁剪
 </a>
</li>

    </ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   模型部署
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     模型序列化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c">
     编写 C++ 程序读取模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id24">
     编译并执行
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="deploy-your-model">
<span id="id1"></span><h1>部署你的模型<a class="headerlink" href="#deploy-your-model" title="永久链接至标题">¶</a></h1>
<div class="section" id="id2">
<h2>模型部署<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>MegEngine 的一大核心优势是“训练推理一体化”，其中“训练”是在 Python 环境中进行的，而“推理”则特指在 C++ 环境下使用训练完成的模型进行推理。而将模型迁移到无需依赖 Python 的环境中，使其能正常进行推理计算，被称为 <strong>部署</strong> 。部署的目的是简化除了模型推理所必需的一切其它依赖，使推理计算的耗时变得尽可能少，比如手机人脸识别场景下会需求毫秒级的优化，而这必须依赖于 C++ 环境才能实现。</p>
<p>本章从一个训练好的异或网络模型（见 <a href="#id3"><span class="problematic" id="id4">`</span></a>MegStudio 项目 <a href="#id5"><span class="problematic" id="id6">`</span></a>_ ）出发，讲解如何将其部署到 CPU（X86）环境下运行。主要分为以下步骤：</p>
<ol class="arabic simple">
<li><p>将模型序列化并导出到文件，详细介绍可见 <span class="xref std std-ref">trace_and_dump</span>；</p></li>
<li><p>编写读取模型的 C++ 脚本；</p></li>
<li><p>编译 C++ 脚本成可执行文件。</p></li>
</ol>
<div class="section" id="id7">
<h3>模型序列化<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
<p>这里我们使用 xor-deploy 的例子，模型定义与序列化代码可见 <a href="#id8"><span class="problematic" id="id9">`</span></a>xornet.py <a href="#id10"><span class="problematic" id="id11">`</span></a>_ 。</p>
</div>
<div class="section" id="c">
<h3>编写 C++ 程序读取模型<a class="headerlink" href="#c" title="永久链接至标题">¶</a></h3>
<p>接下来我们需要编写一个 C++ 程序，来实现我们期望在部署平台上完成的功能。在这里我们基于上面导出的异或网络模型，实现一个最简单的功能，即给定两个浮点数，输出对其做异或操作，结果为 0 的概率以及为 1 的概率。</p>
<p>在此之前，为了能够正常使用 MegEngine 底层 C++ 接口，需要先按照 MegeEngine 中提供的编译脚本( <a href="#id12"><span class="problematic" id="id13">`</span></a>MegEngine/scripts <a href="#id14"><span class="problematic" id="id15">`</span></a>_ )从源码编译得到 MegEngine 的相关库, 通过这些脚本可以交叉编译安卓（ARMv7，ARMv8，ARMv8.2）版本、linux 版本（ARMv7，ARMv8，ARMv8.2）以及 ios 相关库，也可以本机编译 windows/linux/macos 相关库文件。</p>
<p>实现上述异或计算的示例 C++ 代码如下（引自 <a href="#id16"><span class="problematic" id="id17">`</span></a>xor-deploy.cpp <a href="#id18"><span class="problematic" id="id19">`</span></a>_ ）：</p>
<p>简单解释一下代码的意思，我们首先通过 <span class="xref std std-ref">exhale_class_classmgb_1_1serialization_1_1GraphLoader</span> 将模型加载进来，接着通过 <code class="docutils literal notranslate"><span class="pre">tensor_map</span></code> 和上节指定的输入名称 <code class="docutils literal notranslate"><span class="pre">data</span></code> ，找到模型的输入指针，再将运行时提供的输入 <code class="docutils literal notranslate"><span class="pre">x</span></code> 和 <code class="docutils literal notranslate"><span class="pre">y</span></code> 赋值给输入指针，然后我们使用 <code class="docutils literal notranslate"><span class="pre">network.graph-&gt;compile</span></code> 将模型编译成一个函数接口，并调用执行，最后将得到的结果 <code class="docutils literal notranslate"><span class="pre">predict</span></code> 进行输出，该输出的两个值即为异或结果为 0 的概率以及为 1 的概率 。
另外可以配置上面加载模型时候的 <code class="docutils literal notranslate"><span class="pre">config</span></code> 来优化 inference 计算效率，为了加速一般在 ARM 上面配置 <code class="docutils literal notranslate"><span class="pre">enable_nchw44_layout()</span></code> ,在x86 CPU上面配置 <code class="docutils literal notranslate"><span class="pre">enable_nchw88_layout()</span></code> ，具体的配置方法参考 <a href="#id20"><span class="problematic" id="id21">`</span></a>load_and_run 源码 <a href="#id22"><span class="problematic" id="id23">`</span></a>_ 。</p>
</div>
<div class="section" id="id24">
<h3>编译并执行<a class="headerlink" href="#id24" title="永久链接至标题">¶</a></h3>
<p>为了更完整地实现“训练推理一体化”，我们还需要支持同一个 C++ 程序能够交叉编译到不同平台上执行，而不需要修改代码。之所以能够实现不同平台一套代码，是由于底层依赖的算子库（内部称作 MegDNN）实现了对不同平台接口的封装，在编译时会自动根据指定的目标平台选择兼容的接口。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>目前发布的版本我们开放了对 CPU（X86、X64、ARMv7、ARMv8、ARMv8.2）和 GPU（CUDA）平台的 float 和量化 int8 的支持。</p>
</div>
<p>我们在这里以 CPU（X86） 平台为例，如果目标平台是ARM则可以参考 <span class="xref std std-ref">inference_chinese</span> 。首先直接使用 gcc 或者 clang （用 <code class="docutils literal notranslate"><span class="pre">$CXX</span></code> 指代）进行编译即可：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">$CXX</span> -o xor_deploy -I<span class="nv">$MGE_INSTALL_PATH</span>/include xor_deploy.cpp -L<span class="nv">$MGE_INSTALL_PATH</span>/lib/ -lmegengine
</pre></div>
</div>
<p>上面的 <code class="docutils literal notranslate"><span class="pre">$MGE_INSTALL_PATH</span></code> 指代了编译安装时通过 <code class="docutils literal notranslate"><span class="pre">CMAKE_INSTALL_PREFIX</span></code> 指定的安装路径。编译完成之后，通过以下命令执行即可：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$MGE_INSTALL_PATH</span>/lib:<span class="nv">$LD_LIBRARY_PATH</span> ./xor_deploy xornet_deploy.mge <span class="m">0</span>.6 <span class="m">0</span>.9
</pre></div>
</div>
<p>这里将 <code class="docutils literal notranslate"><span class="pre">$MGE_INSTALL_PATH/lib</span></code> 加进 <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code> 环境变量，确保 MegEngine 库可以被编译器找到。上面命令对应的输出如下：</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Predicted: 0.999988 1.2095e-05
</pre></div>
</div>
<p>至此我们便完成了从 Python 模型到 C++ 可执行文件的部署流程，如果需要快速的运行模型以及测试模型性能，请参考 <span class="xref std std-ref">how_to_use_load_and_run</span> 。</p>
</div>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.4bc14ce28f4cf826ca84.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020-2021, The MegEngine Open Source Team.<br/>
        由 <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1 创建。<br/>
    </p>
  </div>
</footer>
  </body>
</html>