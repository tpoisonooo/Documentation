
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>分布式训练 &#8212; MegEngine 1.2.0 文档</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script src="../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="量化训练" href="quantization.html" />
    <link rel="prev" title="用户指南" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
      
      <a class="navbar-brand" href="../index.html">
        <img src="../_static/logo.png" class="logo" alt="logo">
      </a>
      
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../getting-started/index.html">
  新手入门
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  用户指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../reference/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../developmet/index.html">
  开发者指南
 </a>
</li>

        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discuss.megengine.org.cn/">论坛<i class="fas fa-external-link-alt"></i></a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://megengine.org.cn/">官网<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>

      <form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="输入搜索文本..." aria-label="输入搜索文本..." autocomplete="off" >
</form>
      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/MegEngine/MegEngine" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   分布式训练
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="quantization.html">
   量化训练
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="advanced-parameter-optimization.html">
   参数优化进阶配置
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="trace.html">
   动态图转静态图
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="sublinear-memory.html">
   亚线性内存优化
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="dump.html">
   导出序列化模型
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="deploy-your-model.html">
   部署你的模型
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="load-and-run.html">
   模型正确性、速度验证与性能调试
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="codegen.html">
   使用 codegen 减少访存操作
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="midout.html">
   使用 midout 进行端上裁剪
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   单机多卡
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     如何启动一个单机多卡的训练
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     数据处理流程
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     参数同步
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     模型保存与加载
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataloader">
   使用 DataLoader 进行数据加载
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   多机多卡
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   模型并行
  </a>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="distribution-rst">
<span id="id1"></span><h1>分布式训练<a class="headerlink" href="#distribution-rst" title="永久链接至标题">¶</a></h1>
<p>本章我们将介绍如何在 MegEngine 中高效地利用多 GPU 进行分布式训练。
分布式训练是指同时利用一台或者多台机器上的 GPU 进行并行计算。
在深度学习领域，最常见的并行计算方式是在数据层面进行的，
即每个 GPU 各自负责一部分数据，并需要跑通整个训练和推理流程。
这种方式叫做 <strong>数据并行</strong> 。</p>
<p>目前 MegEngine 开放的接口支持单机多卡和多机多卡的数据并行方式。</p>
<div class="section" id="id2">
<h2>单机多卡<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>单机多卡是最为常用的方式，比如单机四卡、单机八卡，足以支持我们完成大部分模型的训练。</p>
<p>本节我们按照以下顺序进行介绍：</p>
<ol class="arabic simple">
<li><p>如何启动一个单机多卡的训练</p></li>
<li><p>数据处理流程</p></li>
<li><p>进程间训练状态如何同步</p></li>
<li><p>如何在多进程环境中将模型保存与加载</p></li>
</ol>
<div class="section" id="id3">
<h3>如何启动一个单机多卡的训练<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>我们提供了一个单机多卡的启动器。代码示例：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.autodiff</span> <span class="k">as</span> <span class="nn">ad</span>
<span class="kn">import</span> <span class="nn">megengine.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">megengine.optimizer</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="nd">@dist</span><span class="o">.</span><span class="n">launcher</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

<span class="c1"># ... 模型初始化</span>

<span class="n">dist</span><span class="o">.</span><span class="n">bcast_list_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">GradManager</span><span class="p">()</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">make_allreduce_cb</span><span class="p">(</span><span class="s2">&quot;sum&quot;</span><span class="p">)])</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

<span class="c1"># ... 你的训练代码</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h3>数据处理流程<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>用 <a class="reference internal" href="../reference/api/megengine.distributed.launcher.html#megengine.distributed.launcher" title="megengine.distributed.launcher"><code class="xref py py-class docutils literal notranslate"><span class="pre">launcher</span></code></a> 启动之后，我们便可以按照正常的流程进行训练了，
但是由于需要每个进程处理不同的数据，我们还需要在数据部分做一些额外的操作。</p>
<p>在这里我们以载入 MNIST 数据为例，展示如何对数据做切分，使得每个进程拿到不重叠的数据。
此处我们将整个数据集载入内存后再进行切分。
这种方式比较低效，仅作为原理示意，更加高效的方式见 <a class="reference internal" href="#dist-dataloader"><span class="std std-ref">使用 DataLoader 进行数据加载</span></a> 。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_datasets</span> <span class="o">=</span> <span class="n">load_mnist_datasets</span><span class="p">()</span> <span class="c1"># 下载并读取 MNIST 数据集，见“数据加载”文档</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">label_train</span> <span class="o">=</span> <span class="n">mnist_datasets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span> <span class="c1"># 得到训练集的数据和标签</span>

<span class="n">size</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_devices</span><span class="p">)</span> <span class="c1"># 将所有数据划分为 num_devices 份</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">size</span> <span class="o">*</span> <span class="n">rank</span> <span class="c1"># 得到本进程负责的数据段的起始索引</span>
<span class="n">r</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_train</span><span class="p">))</span> <span class="c1"># 得到本进程负责的数据段的终点索引</span>
<span class="n">data_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="n">l</span><span class="p">:</span><span class="n">r</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="c1"># 得到本进程的数据</span>
<span class="n">label_train</span> <span class="o">=</span> <span class="n">label_train</span><span class="p">[</span><span class="n">l</span><span class="p">:</span><span class="n">r</span><span class="p">]</span> <span class="c1"># 得到本进程的标签</span>
</pre></div>
</div>
<p>至此我们便得到了每个进程各自负责的、互不重叠的数据部分。</p>
</div>
<div class="section" id="id5">
<h3>参数同步<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<p>初始化模型的参数之后，我们可以调用 <a class="reference internal" href="../reference/api/megengine.distributed.bcast_list_.html#megengine.distributed.bcast_list_" title="megengine.distributed.bcast_list_"><code class="xref py py-func docutils literal notranslate"><span class="pre">bcast_list_</span></code></a> 对进程间模型的参数进行广播同步：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Le_Net</span><span class="p">()</span>
<span class="n">dist</span><span class="o">.</span><span class="n">bcast_list_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</pre></div>
</div>
<p>在反向传播求梯度的步骤中，我们通过插入 callback 函数的形式，
对各个进程计算出的梯度进行累加，各个进程都拿到的是累加后的梯度。代码示例：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.autodiff</span> <span class="k">as</span> <span class="nn">ad</span>
<span class="kn">import</span> <span class="nn">megengine.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Le_Net</span><span class="p">()</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">GradManager</span><span class="p">()</span>
<span class="c1"># sum 表示累加方式是直接相加 ，如果填写 mean 就是相加后求平均</span>
<span class="c1"># dist.WORLD 表示梯度累加的范围，默认是 dist.WORLD 表示所有进程间都进行同步</span>
<span class="n">gm</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">make_allreduce_cb</span><span class="p">(</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">WORLD</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="section" id="id6">
<h3>模型保存与加载<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<p>在 MegEngine 中，依赖于上面提到的状态同步机制，我们保持了各个进程状态的一致，
因此可以很容易地实现模型的保存和加载。</p>
<p>对于加载，我们只要在主进程（rank 0 进程）中加载模型参数，
然后调用 <a class="reference internal" href="../reference/api/megengine.distributed.bcast_list_.html#megengine.distributed.bcast_list_" title="megengine.distributed.bcast_list_"><code class="xref py py-func docutils literal notranslate"><span class="pre">bcast_list_</span></code></a> 对各个进程的参数进行同步，就保持了各个进程的状态一致。</p>
<p>对于保存，由于我们在梯度计算中插入了 callback 函数对各个进程的梯度进行累加，
所以我们进行参数更新后的参数还是一致的，可以直接保存。</p>
<p>可以参考以下示例代码实现：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 加载模型参数</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;net&#39;</span><span class="p">])</span>
<span class="n">dist</span><span class="o">.</span><span class="n">bcast_list_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">GradManager</span><span class="p">()</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">make_allreduce_cb</span><span class="p">(</span><span class="s2">&quot;sum&quot;</span><span class="p">)])</span>

<span class="c1"># ... 训练代码</span>

<span class="c1"># 保存模型参数</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;net&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">best_acc</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">mge</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="dataloader">
<span id="dist-dataloader"></span><h2>使用 DataLoader 进行数据加载<a class="headerlink" href="#dataloader" title="永久链接至标题">¶</a></h2>
<p>在上一节，为了简单起见，我们将整个数据集全部载入内存。
实际中，我们可以通过 <a class="reference internal" href="../reference/api/megengine.data.DataLoader.html#megengine.data.DataLoader" title="megengine.data.DataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a> 来更高效地加载数据。</p>
<p><a class="reference internal" href="../reference/api/megengine.data.DataLoader.html#megengine.data.DataLoader" title="megengine.data.DataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a> 会自动帮我们处理分布式训练时数据相关的问题，
可以实现使用单卡训练时一样的数据加载代码，具体来说：</p>
<ul class="simple">
<li><p>所有采样器 <a class="reference internal" href="../reference/api/megengine.data.Sampler.html#megengine.data.Sampler" title="megengine.data.Sampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">Sampler</span></code></a> 都会自动地做类似上文中数据切分的操作，
使得所有进程都能获取互不重复的数据。</p></li>
<li><p>每个进程的 <a class="reference internal" href="../reference/api/megengine.data.DataLoader.html#megengine.data.DataLoader" title="megengine.data.DataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a> 还会自动调用分布式相关接口实现内存共享，
避免不必要的内存占用，从而显著加速数据读取。</p></li>
</ul>
<p>总之，在分布式训练时，你无需对使用 <a class="reference internal" href="../reference/api/megengine.data.DataLoader.html#megengine.data.DataLoader" title="megengine.data.DataLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a> 的方式进行任何修改，
一切都能无缝地切换。完整的例子见 MegEngine/<a class="reference external" href="https://github.com/MegEngine/Models">Models</a> 存储库。</p>
</div>
<div class="section" id="id7">
<h2>多机多卡<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h2>
<p>在 MegEngine 中，我们能很方便地将上面单机多卡的代码修改为多机多卡，
只需修改传给 <code class="xref py py-func docutils literal notranslate"><span class="pre">launcher</span></code> 的参数就可以进行多机多卡训练</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.autodiff</span> <span class="k">as</span> <span class="nn">ad</span>
<span class="kn">import</span> <span class="nn">megengine.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">megengine.optimizer</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="nd">@dist</span><span class="o">.</span><span class="n">launcher</span><span class="p">(</span><span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
               <span class="n">n_gpus</span><span class="o">=</span><span class="n">n_gpus</span><span class="p">,</span>
               <span class="n">rank_start</span><span class="o">=</span><span class="n">rank_start</span><span class="p">,</span>
               <span class="n">master_ip</span><span class="o">=</span><span class="n">master_ip</span><span class="p">,</span>
               <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

    <span class="c1"># ... 模型初始化</span>

    <span class="n">dist</span><span class="o">.</span><span class="n">bcast_list_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">gm</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">GradManager</span><span class="p">()</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">make_allreduce_cb</span><span class="p">(</span><span class="s2">&quot;sum&quot;</span><span class="p">)])</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

    <span class="c1"># ... 你的训练代码</span>
</pre></div>
</div>
<p>其中 <code class="docutils literal notranslate"><span class="pre">world_size</span></code> 是你训练的用到的总卡数， <code class="docutils literal notranslate"><span class="pre">n_gpus</span></code> 是你运行时这台物理机的卡数，
<code class="docutils literal notranslate"><span class="pre">rank_start</span></code> 是这台机器的 rank 起始值，<code class="docutils literal notranslate"><span class="pre">master_ip</span></code> 是 rank 0 所在机器的 ip 地址，
<code class="docutils literal notranslate"><span class="pre">port</span></code> 是分布式训练 master server 使用的端口号</p>
<p>其它部分与单机版本完全相同。最终只需在每个机器上执行相同的 Python 程序，即可实现多机多卡的分布式训练。</p>
</div>
<div class="section" id="id8">
<h2>模型并行<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h2>
<p>在 MegEngine 中，也支持模型并行的方式来做训练。</p>
<p>最简单的模型并行就是把一个模型拆分成上下两个部分来做，在 MegEngine 中可以简单的实现。</p>
<p>下面是一个简单的例子来展示怎么写一个模型并行的训练：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine</span> <span class="k">as</span> <span class="nn">mge</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">megengine.module</span> <span class="k">as</span> <span class="nn">M</span>
<span class="kn">import</span> <span class="nn">megengine.autodiff</span> <span class="k">as</span> <span class="nn">ad</span>
<span class="kn">import</span> <span class="nn">megengine.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">megengine.optimizer</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="nd">@dist</span><span class="o">.</span><span class="n">launcher</span><span class="p">(</span><span class="n">n_gpus</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
    <span class="c1"># client 用于各个 rank 之间互相通信</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_client</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">layer1</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 模型上半部分</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">mge</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">gm</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">GradManager</span><span class="p">()</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">layer1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">gm</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">layer1</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

        <span class="k">with</span> <span class="n">gm</span><span class="p">:</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">client</span><span class="o">.</span><span class="n">user_set</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="c1"># 因为 numpy.dtype 类型不能直接发送，所以转化为 str 类型</span>
            <span class="n">client</span><span class="o">.</span><span class="n">user_set</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">remote_send</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">dest_rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">gm</span><span class="o">.</span><span class="n">backward</span><span class="p">([])</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span><span class="o">.</span><span class="n">clear_grad</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">layer2</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 模型下半部分</span>

        <span class="n">gm</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">GradManager</span><span class="p">()</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">layer2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">gm</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">layer2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

        <span class="k">with</span> <span class="n">gm</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">user_get</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">)</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">user_get</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">remote_recv</span><span class="p">(</span><span class="n">src_rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">layer2</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
            <span class="n">gm</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span><span class="o">.</span><span class="n">clear_grad</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020-2021, The MegEngine Open Source Team.<br/>
        由 <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2 创建。<br/>
    </p>
  </div>
</footer>
  </body>
</html>