
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>参数优化进阶配置 &#8212; MegEngine 1.3.0 文档</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.93dda2a1e4f2b831d8345b5b3dbee4ea.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3c6125c0ae68274ddd1b.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script src="../../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="将动态图转为静态图" href="trace.html" />
    <link rel="prev" title="安装 MegEngine" href="../install/index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
      
      <a class="navbar-brand" href="../../index.html">
        <img src="../../_static/logo.png" class="logo" alt="logo">
      </a>
      
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../getting-started/index.html">
  新手入门
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  用户指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reference/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../development/index.html">
  开发者指南
 </a>
</li>

        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discuss.megengine.org.cn/">论坛<i class="fas fa-external-link-alt"></i></a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://megengine.org.cn/">官网<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>

      <form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="输入搜索文本..." aria-label="输入搜索文本..." autocomplete="off" >
</form>
      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/MegEngine/MegEngine" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>

      <script type="text/javascript">
  (function () {
    window.versionSwitcher = {
      pageName: "user-guide/model-development/advanced-parameter-optimization.html",
      versionJsonUrl: "/doc/version.json",
      enableLocaleSupport: "True" === "True",
      // TODO read from "zh, en"
      allLocales: [
        {
          "locale": "zh",
          "display": "中文"
        },
        {
          "locale": "en",
          "display": "EN"
        }
      ]
    }
  })();
</script>

<ul class="navbar-nav">
  <li class="nav-item dropdown">
    <button id="version-dropdown" class="btn btn-secondary btn-sm dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      <!-- placeholder for javascript filling above -->
    </button>
    <div id="version-menu" class="dropdown-menu" style="min-width: 6rem;">
      <!-- placeholder for javascript filling above -->
    </div>
  </li>
  <li class="nav-item">
    <span id="locale-switcher">
      <!-- placeholder for locale switcher -->
    </span>
  </li>
</ul>
      
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p class="caption">
 <span class="caption-text">
  安装
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../install/index.html">
   安装 MegEngine
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  模型开发
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   参数优化进阶配置
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trace.html">
   将动态图转为静态图
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dump.html">
   导出模型序列化文件
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  分布式训练
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../distributed-training.html">
   分布式训练
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  模型压缩
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../model-compression/quantization.html">
   量化
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  模型部署
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/index.html">
   将模型部署到 C++ 环境
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/midout.html">
   减少二进制文件体积
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  各类工具
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/module-stats.html">
   参数量与计算量统计
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/runtimeopr.html">
   RuntimeOpr 使用说明
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/graphsurgeon.html">
   图手术操作指南
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/load-and-run.html">
   如何使用 Load and Run（C++）
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/load-and-run-py.html">
   如何使用 Load and Run（Python）
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   不同参数使用不同的学习速率
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   训练中对学习速率的更改
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   不同参数使用不同的优化器
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   固定部分参数不优化
  </a>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="advanced-parameter-optimization">
<span id="id1"></span><h1>参数优化进阶配置<a class="headerlink" href="#advanced-parameter-optimization" title="永久链接至标题">¶</a></h1>
<p>假定网络使用如下优化器进行训练：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.optimizer</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">le_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>    <span class="c1"># 参数列表，将指定参数与优化器绑定</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>                <span class="c1"># 学习速率</span>
<span class="p">)</span>
</pre></div>
</div>
<p>这个优化器对所有参数都使用同一学习速率进行优化，本章将介绍如何做到对不同的参数采用不同的学习速率。</p>
<div class="section" id="id2">
<h2>不同参数使用不同的学习速率<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p><a class="reference internal" href="../../reference/api/megengine.optimizer.Optimizer.html#megengine.optimizer.Optimizer" title="megengine.optimizer.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a> 支持将网络的参数进行分组，
不同的参数组可以采用不同的学习速率进行训练。 一个参数组由一个字典表示，这个字典中有</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'params':</span> <span class="pre">param_list</span></code> ，用来指定参数组包含的参数。此键值对必须有。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'lr':</span> <span class="pre">learning_rate</span></code> ，用来指定此参数组的学习速率。此键值对有时可省略，省略后参数组的学习速率由优化器指定。</p></li>
</ul>
<p>所有待优化参数组的字典会组成一个列表作为 <a class="reference internal" href="../../reference/api/megengine.optimizer.Optimizer.html#megengine.optimizer.Optimizer" title="megengine.optimizer.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a> 实例化时的第一个参数传入。</p>
<p>为了更好的说明参数组，我们首先使用 <a class="reference internal" href="../../reference/api/megengine.module.Module.html#megengine.module.Module" title="megengine.module.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> 提供的
<code class="xref py py-meth docutils literal notranslate"><span class="pre">named_parameters</span></code> 函数来对网络参数进行分组。
这个函数返回一个包含网络所有参数并且以参数名字为键、参数变量为值的字典：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="ow">in</span> <span class="n">le_net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># 打印参数的名字和对应张量的形状</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>classifer.bias (10,)
classifer.weight (10, 84)
conv1.bias (1, 6, 1, 1)
conv1.weight (6, 1, 5, 5)
conv2.bias (1, 16, 1, 1)
conv2.weight (16, 6, 5, 5)
fc1.bias (120,)
fc1.weight (120, 400)
fc2.bias (84,)
fc2.weight (84, 120)
</pre></div>
</div>
<p>根据参数的名字我们可以将 <code class="docutils literal notranslate"><span class="pre">LeNet</span></code> 中所有卷积的参数分为一组，所有全连接层的参数分为另一组：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">conv_param_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fc_param_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="ow">in</span> <span class="n">le_net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="c1"># 所有卷积的参数为一组，所有全连接层的参数为另一组</span>
    <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
        <span class="n">conv_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fc_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
</pre></div>
</div>
<p>分组后即可根据下述代码对不同参数组设置不同的学习速率：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.optimizer</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="c1"># 参数组列表即param_groups，每个参数组都可以自定义学习速率，也可不自定义，统一使用优化器设置的学习速率</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">conv_param_list</span><span class="p">},</span>            <span class="c1"># 卷积参数所属的参数组，未自定义学习速率</span>
        <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">fc_param_list</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">}</span>   <span class="c1"># 全连接层参数所属的参数组，自定义学习速率为0.01</span>
    <span class="p">],</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>  <span class="c1"># 参数组例表中未指定学习速率的参数组服从此设置，如所有卷积参数</span>
<span class="p">)</span>
</pre></div>
</div>
<p>优化器中设置的参数组列表对应于 <code class="xref py py-attr docutils literal notranslate"><span class="pre">param_groups</span></code> 属性。
我们可以通过其获取不同参数组的学习速率。</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 打印每个参数组所含参数的数量和对应的学习速率</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">]),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">]),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>4 0.05
6 0.01
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h2>训练中对学习速率的更改<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<p>MegEngine 也支持在训练过程中对学习速率进行修改，比如部分参数训练到一定程度后就不再需要优化，
此时将对应参数组的学习速率设为零即可。我们修改训练代码进行示例说明。
修改后的训练代码总共训练四个epoch，我们会在第二个epoch结束时将所有全连接层参数的学习速率置零，
并在每个epoch当中输出 <code class="docutils literal notranslate"><span class="pre">LeNet</span></code> 中全连接层的部分参数值以显示是否被更新。</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;original parameter: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">train_func</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span><span class="p">,</span> <span class="n">le_net</span><span class="p">,</span> <span class="n">gm</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># 根据梯度更新参数值</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">clear_grad</span><span class="p">()</span> <span class="c1"># 将参数的梯度置零</span>

    <span class="c1"># 输出 LeNet 中全连接层的部分参数值</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch: </span><span class="si">{}</span><span class="s2">, parameter: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;params&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># 将所有全连接层参数的学习速率改为0.0</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">set lr zero</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>original parameter: Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], device=xpux:0)
epoch: 0, parameter: Tensor([-0.0102  0.0082  0.0062 -0.0093 -0.0018  0.0132 -0.0064  0.0077 -0.0005 -0.007 ], device=xpux:0)
epoch: 1, parameter: Tensor([-0.0094  0.008   0.0066 -0.0105 -0.0026  0.0141 -0.008   0.0073  0.0015 -0.0071], device=xpux:0)

set lr zero

epoch: 2, parameter: Tensor([-0.0094  0.008   0.0066 -0.0105 -0.0026  0.0141 -0.008   0.0073  0.0015 -0.0071], device=xpux:0)
epoch: 3, parameter: Tensor([-0.0094  0.008   0.0066 -0.0105 -0.0026  0.0141 -0.008   0.0073  0.0015 -0.0071], device=xpux:0)
</pre></div>
</div>
<p>从输出可以看到在学习速率设为0之前参数值是在不断更新的，但是在设为0之后参数值就不再变化。</p>
<p>同时多数网络在训练当中会不断减小学习速率，如下代码展示了 MegEngine 是如何在训练过程中线性减小学习速率的：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="c1"># 初始学习速率</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_epochs</span><span class="p">):</span>
    <span class="c1"># 设置当前epoch的学习速率</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span> <span class="c1"># param_groups中包含所有需要此优化器更新的参数</span>
        <span class="c1"># 学习速率线性递减，每个epoch调整一次</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h2>不同参数使用不同的优化器<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h2>
<p>对于不同的参数，也可以使用不同的优化器对它们分别优化。
对参数的梯度置零（ <code class="xref py py-meth docutils literal notranslate"><span class="pre">clear_grad</span></code> ）
和更新（ <code class="xref py py-meth docutils literal notranslate"><span class="pre">step</span></code> ）操作，
如果所有优化器都是同时进行的，可以定义一个 <code class="docutils literal notranslate"><span class="pre">MultipleOptimizer</span></code> 类。
在初始化时声明多个不同的优化器，在调用置零函数和更新函数时对所有优化器执行对应操作。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultipleOptimizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">opts</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span>

    <span class="k">def</span> <span class="nf">clear_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">:</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">clear_grad</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">opts</span><span class="p">:</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>假设想用 <a class="reference internal" href="../../reference/api/megengine.optimizer.SGD.html#megengine.optimizer.SGD" title="megengine.optimizer.SGD"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGD</span></code></a> 优化所有卷积参数，
用 <code class="xref py py-class docutils literal notranslate"><span class="pre">Adam</span></code> 优化所有全连接层参数。
可以按照如下方式定义优化器，不需要改变训练代码就可以达到不同的参数使用不同的优化器优化的效果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">MultipleOptimizer</span><span class="p">(</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">conv_param_list</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">fc_param_list</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>如果不同的参数梯度置零和更新不是同时进行的，你只需要定义多个优化器，在不同的时间调用对应的函数即可。</p>
</div>
<div class="section" id="id5">
<h2>固定部分参数不优化<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h2>
<p>除了将不训练的参数分为一组并将学习速率设为零外，
MegEngine 还提供了其他途径来固定参数不进行优化：
仅将需要优化的参数与求导器和优化器绑定即可。
如下代码所示，仅对 <code class="docutils literal notranslate"><span class="pre">LeNet</span></code> 中的卷积参数进行优化：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">megengine.optimizer</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">megengine.autodiff</span> <span class="kn">import</span> <span class="n">GradManager</span>

<span class="n">le_net</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="n">param_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="ow">in</span> <span class="n">le_net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="s1">&#39;conv&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span> <span class="c1"># 仅训练LeNet中的卷积参数</span>
        <span class="n">param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">param_list</span><span class="p">,</span> <span class="c1"># 参数</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>    <span class="c1"># 学习速率</span>
<span class="p">)</span>

<span class="n">gm</span> <span class="o">=</span> <span class="n">GradManager</span><span class="p">()</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">param_list</span><span class="p">)</span>
</pre></div>
</div>
<p>下述代码将上面的设置加入到了具体训练当中，能够更加直观的看到各个参数的梯度差异：</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># 为了减少输出，本次训练仅训练一个epoch</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_epochs</span><span class="p">):</span>
    <span class="c1"># 设置当前epoch的学习速率</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_epochs</span><span class="p">)</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">batch_label</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">batch_label</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">train_func</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">batch_label</span><span class="p">,</span> <span class="n">le_net</span><span class="p">,</span> <span class="n">gm</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># 根据梯度更新参数值</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">clear_grad</span><span class="p">()</span> <span class="c1"># 将参数的梯度置零</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># 输出每个参数的梯度</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="ow">in</span> <span class="n">le_net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>classifier.bias None
classifier.weight None
conv1.bias Tensor([-0.0432], device=xpux:0)
conv1.weight Tensor([0.1256], device=xpux:0)
conv2.bias Tensor([0.0147], device=xpux:0)
conv2.weight Tensor([5.0205], device=xpux:0)
fc1.bias None
fc1.weight None
fc2.bias None
fc2.weight None
</pre></div>
</div>
<p>从输出可以看到除了卷积参数有梯度外其余参数均没有梯度也就不会更新。</p>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.3c6125c0ae68274ddd1b.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020-2021, The MegEngine Open Source Team.<br/>
        由 <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3 创建。<br/>
    </p>
  </div>
</footer>
  </body>
</html>