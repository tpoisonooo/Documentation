
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>megengine.functional.nn &#8212; MegEngine 1.3.0 文档</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.93dda2a1e4f2b831d8345b5b3dbee4ea.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3c6125c0ae68274ddd1b.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
      
      <a class="navbar-brand" href="../../../index.html">
        <img src="../../../_static/logo.png" class="logo" alt="logo">
      </a>
      
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../getting-started/index.html">
  新手入门
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../user-guide/index.html">
  用户指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../reference/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../development/index.html">
  开发者指南
 </a>
</li>

        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discuss.megengine.org.cn/">论坛<i class="fas fa-external-link-alt"></i></a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://megengine.org.cn/">官网<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>

      <form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="输入搜索文本..." aria-label="输入搜索文本..." autocomplete="off" >
</form>
      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/MegEngine/MegEngine" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>

      <script type="text/javascript">
  (function () {
    window.versionSwitcher = {
      pageName: "_modules/megengine/functional/nn.html",
      versionJsonUrl: "/doc/version.json",
      enableLocaleSupport: "True" === "True",
      // TODO read from "zh, en"
      allLocales: [
        {
          "locale": "zh",
          "display": "中文"
        },
        {
          "locale": "en",
          "display": "EN"
        }
      ]
    }
  })();
</script>

<ul class="navbar-nav">
  <li class="nav-item dropdown">
    <button id="version-dropdown" class="btn btn-secondary btn-sm dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      <!-- placeholder for javascript filling above -->
    </button>
    <div id="version-menu" class="dropdown-menu" style="min-width: 6rem;">
      <!-- placeholder for javascript filling above -->
    </div>
  </li>
  <li class="nav-item">
    <span id="locale-switcher">
      <!-- placeholder for locale switcher -->
    </span>
  </li>
</ul>
      
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    
</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>megengine.functional.nn 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># MegEngine is Licensed under the Apache License, Version 2.0 (the &quot;License&quot;)</span>
<span class="c1">#</span>
<span class="c1"># Copyright (c) 2014-2021 Megvii Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an</span>
<span class="c1"># &quot;AS IS&quot; BASIS, WITHOUT ARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># pylint: disable=too-many-lines</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">..core._imperative_rt.core2</span> <span class="kn">import</span> <span class="n">apply</span>
<span class="kn">from</span> <span class="nn">..core._imperative_rt.graph</span> <span class="kn">import</span> <span class="n">VarNode</span>
<span class="kn">from</span> <span class="nn">..core._trace_option</span> <span class="kn">import</span> <span class="n">use_symbolic_shape</span>
<span class="kn">from</span> <span class="nn">..core.ops</span> <span class="kn">import</span> <span class="n">builtin</span>
<span class="kn">from</span> <span class="nn">..core.ops.builtin</span> <span class="kn">import</span> <span class="n">BatchNorm</span><span class="p">,</span> <span class="n">Elemwise</span>
<span class="kn">from</span> <span class="nn">..core.ops.special</span> <span class="kn">import</span> <span class="n">Const</span>
<span class="kn">from</span> <span class="nn">..core.tensor</span> <span class="kn">import</span> <span class="n">megbrain_graph</span><span class="p">,</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">..core.tensor.array_method</span> <span class="kn">import</span> <span class="n">_elwise_apply</span>
<span class="kn">from</span> <span class="nn">..core.tensor.utils</span> <span class="kn">import</span> <span class="n">astensor1d</span><span class="p">,</span> <span class="n">astype</span><span class="p">,</span> <span class="n">setscalar</span>
<span class="kn">from</span> <span class="nn">..device</span> <span class="kn">import</span> <span class="n">get_default_device</span>
<span class="kn">from</span> <span class="nn">..distributed</span> <span class="kn">import</span> <span class="n">WORLD</span><span class="p">,</span> <span class="n">is_distributed</span>
<span class="kn">from</span> <span class="nn">..random</span> <span class="kn">import</span> <span class="n">uniform</span>
<span class="kn">from</span> <span class="nn">..tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">..utils.deprecation</span> <span class="kn">import</span> <span class="n">deprecated_func</span>
<span class="kn">from</span> <span class="nn">..utils.tuple_function</span> <span class="kn">import</span> <span class="n">_pair</span><span class="p">,</span> <span class="n">_pair_nonzero</span><span class="p">,</span> <span class="n">_triple</span><span class="p">,</span> <span class="n">_triple_nonzero</span>
<span class="kn">from</span> <span class="nn">.debug_param</span> <span class="kn">import</span> <span class="n">get_execution_strategy</span>
<span class="kn">from</span> <span class="nn">.distributed</span> <span class="kn">import</span> <span class="n">all_reduce_sum</span>
<span class="kn">from</span> <span class="nn">.elemwise</span> <span class="kn">import</span> <span class="n">_elwise</span><span class="p">,</span> <span class="n">exp</span><span class="p">,</span> <span class="n">floor</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">log1p</span><span class="p">,</span> <span class="n">maximum</span><span class="p">,</span> <span class="n">minimum</span>
<span class="kn">from</span> <span class="nn">.math</span> <span class="kn">import</span> <span class="n">argsort</span><span class="p">,</span> <span class="n">matmul</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">prod</span><span class="p">,</span> <span class="nb">sum</span>
<span class="kn">from</span> <span class="nn">.tensor</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">broadcast_to</span><span class="p">,</span>
    <span class="n">concat</span><span class="p">,</span>
    <span class="n">expand_dims</span><span class="p">,</span>
    <span class="n">full</span><span class="p">,</span>
    <span class="n">ones</span><span class="p">,</span>
    <span class="n">reshape</span><span class="p">,</span>
    <span class="n">squeeze</span><span class="p">,</span>
    <span class="n">zeros</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;adaptive_avg_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adaptive_max_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;avg_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;batch_norm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv3d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv_transpose2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;deformable_conv2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;deformable_psroi_pooling&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dropout&quot;</span><span class="p">,</span>
    <span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
    <span class="s2">&quot;indexing_one_hot&quot;</span><span class="p">,</span>
    <span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
    <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="s2">&quot;local_conv2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;logsigmoid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;logsumexp&quot;</span><span class="p">,</span>
    <span class="s2">&quot;logsoftmax&quot;</span><span class="p">,</span>
    <span class="s2">&quot;max_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;one_hot&quot;</span><span class="p">,</span>
    <span class="s2">&quot;prelu&quot;</span><span class="p">,</span>
    <span class="s2">&quot;softmax&quot;</span><span class="p">,</span>
    <span class="s2">&quot;softplus&quot;</span><span class="p">,</span>
    <span class="s2">&quot;sync_batch_norm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;hsigmoid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
    <span class="s2">&quot;relu6&quot;</span><span class="p">,</span>
    <span class="s2">&quot;hswish&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resize&quot;</span><span class="p">,</span>
    <span class="s2">&quot;remap&quot;</span><span class="p">,</span>
    <span class="s2">&quot;warp_affine&quot;</span><span class="p">,</span>
    <span class="s2">&quot;warp_perspective&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">expand_hw</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># NOTE: &gt;1d array is accepted, as long as 1 &lt;= size &lt;= 2</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">linear</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a linear transformation to the input tensor.</span>

<span class="sd">    Refer to :class:`~.module.linear.Linear` for more information.</span>

<span class="sd">    :param inp: input tensor with shape `(N, in_features)`.</span>
<span class="sd">    :param weight: weight with shape `(out_features, in_features)`.</span>
<span class="sd">    :param bias: bias with shape `(out_features,)`.</span>
<span class="sd">        Default: None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">ret</span>


<div class="viewcode-block" id="conv2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.conv2d.html#megengine.functional.conv2d">[文档]</a><span class="k">def</span> <span class="nf">conv2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    2D convolution operation.</span>

<span class="sd">    Refer to :class:`~.module.Conv2d` for more information.</span>

<span class="sd">    :param inp: feature map of the convolution operation.</span>
<span class="sd">    :param weight: convolution kernel.</span>
<span class="sd">    :param bias: bias added to the result of convolution (if given).</span>
<span class="sd">    :param stride: stride of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param padding: size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: dilation of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups into which the input and output channels are divided, </span>
<span class="sd">        so as to perform a ``grouped convolution``. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by ``groups``,</span>
<span class="sd">        and the shape of weight should be `(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)`.</span>
<span class="sd">    :type conv_mode: string or :class:`Convolution.Mode`</span>
<span class="sd">    :param conv_mode: supports &quot;CROSS_CORRELATION&quot;. Default:</span>
<span class="sd">        &quot;CROSS_CORRELATION&quot;</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: when set to &quot;DEFAULT&quot;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &quot;FLOAT32&quot;,</span>
<span class="sd">        &quot;Float32&quot; would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">sparse_type</span> <span class="o">=</span> <span class="s2">&quot;DENSE&quot;</span> <span class="k">if</span> <span class="n">groups</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;GROUP&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Convolution</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="n">sparse_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="conv3d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.conv3d.html#megengine.functional.conv3d">[文档]</a><span class="k">def</span> <span class="nf">conv3d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    3D convolution operation.</span>

<span class="sd">    Refer to :class:`~.Conv3d` for more information.</span>

<span class="sd">    :param inp: feature map of the convolution operation.</span>
<span class="sd">    :param weight: convolution kernel.</span>
<span class="sd">    :param bias: bias added to the result of convolution (if given).</span>
<span class="sd">    :param stride: stride of the 3D convolution operation. Default: 1</span>
<span class="sd">    :param padding: size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: dilation of the 3D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups into which the input and output channels are divided, so as to perform a ``grouped convolution``. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by ``groups``,</span>
<span class="sd">        and the shape of weight should be `(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, t, height, width)`.</span>
<span class="sd">    :param conv_mode: supports &quot;CROSS_CORRELATION&quot;. Default:</span>
<span class="sd">        &quot;CROSS_CORRELATION&quot;</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>

    <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>

    <span class="n">pad</span> <span class="o">=</span> <span class="n">_triple</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">_triple_nonzero</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">dilate</span> <span class="o">=</span> <span class="n">_triple_nonzero</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">sparse_type</span> <span class="o">=</span> <span class="s2">&quot;DENSE&quot;</span> <span class="k">if</span> <span class="n">groups</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;GROUP&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Convolution3D</span><span class="p">(</span>
        <span class="n">pad_d</span><span class="o">=</span><span class="n">pad</span><span class="p">[</span><span class="n">D</span><span class="p">],</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad</span><span class="p">[</span><span class="n">H</span><span class="p">],</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad</span><span class="p">[</span><span class="n">W</span><span class="p">],</span>
        <span class="n">stride_d</span><span class="o">=</span><span class="n">stride</span><span class="p">[</span><span class="n">D</span><span class="p">],</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride</span><span class="p">[</span><span class="n">H</span><span class="p">],</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride</span><span class="p">[</span><span class="n">W</span><span class="p">],</span>
        <span class="n">dilate_d</span><span class="o">=</span><span class="n">dilate</span><span class="p">[</span><span class="n">D</span><span class="p">],</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate</span><span class="p">[</span><span class="n">H</span><span class="p">],</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate</span><span class="p">[</span><span class="n">W</span><span class="p">],</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="n">sparse_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="conv_transpose2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.conv_transpose2d.html#megengine.functional.conv_transpose2d">[文档]</a><span class="k">def</span> <span class="nf">conv_transpose2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    2D transposed convolution operation.</span>

<span class="sd">    Refer to :class:`~.ConvTranspose2d` for more information.</span>

<span class="sd">    :param inp: feature map of the convolution operation.</span>
<span class="sd">    :param weight: convolution kernel.</span>
<span class="sd">    :param bias: bias added to the result of convolution (if given).</span>
<span class="sd">    :param stride: stride of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param padding: size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: dilation of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups into which the input and output channels are divided, </span>
<span class="sd">        so as to perform a ``grouped convolution``. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by groups,</span>
<span class="sd">        and the shape of weight should be `(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)`. Default: 1</span>
<span class="sd">    :type conv_mode: string or :class:`Convolution.Mode`</span>
<span class="sd">    :param conv_mode: supports &quot;CROSS_CORRELATION&quot;. Default:</span>
<span class="sd">        &quot;CROSS_CORRELATION&quot;</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: when set to &quot;DEFAULT&quot;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &quot;FLOAT32&quot;,</span>
<span class="sd">        &quot;Float32&quot; would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>

    <span class="k">if</span> <span class="n">groups</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;group transposed conv2d is not supported yet.&quot;</span><span class="p">)</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">ConvolutionBackwardData</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="n">weight</span><span class="p">,</span> <span class="n">inp</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="deformable_conv2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.deformable_conv2d.html#megengine.functional.deformable_conv2d">[文档]</a><span class="k">def</span> <span class="nf">deformable_conv2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">offset</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deformable Convolution.</span>

<span class="sd">    :param inp: input feature map.</span>
<span class="sd">    :param weight: convolution kernel.</span>
<span class="sd">    :param offset: input offset to kernel, channel of this tensor should match the deformable settings.</span>
<span class="sd">    :param mask: input mask to kernel, channel of this tensor should match the deformable settings.</span>
<span class="sd">    :param bias: bias added to the result of convolution (if given).</span>
<span class="sd">    :param stride: stride of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param padding: size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: dilation of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups into which the input and output channels are divided, </span>
<span class="sd">        so as to perform a ``grouped convolution``. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by groups,</span>
<span class="sd">        and the shape of weight should be `(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)`. Default: 1</span>
<span class="sd">    :type conv_mode: string or :class:`Convolution.Mode`</span>
<span class="sd">    :param conv_mode: supports &quot;CROSS_CORRELATION&quot;. Default:</span>
<span class="sd">        &quot;CROSS_CORRELATION&quot;</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: when set to &quot;DEFAULT&quot;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &quot;FLOAT32&quot;,</span>
<span class="sd">        &quot;Float32&quot; would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">sparse_type</span> <span class="o">=</span> <span class="s2">&quot;DENSE&quot;</span> <span class="k">if</span> <span class="n">groups</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;GROUP&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">DeformableConv</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="n">sparse_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<span class="k">def</span> <span class="nf">local_conv2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies spatial 2D convolution over an groupped channeled image with untied kernels.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">GroupLocal</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="s2">&quot;DENSE&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span>


<div class="viewcode-block" id="max_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.max_pool2d.html#megengine.functional.max_pool2d">[文档]</a><span class="k">def</span> <span class="nf">max_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D max pooling over an input tensor.</span>

<span class="sd">    Refer to :class:`~.MaxPool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param kernel_size: size of the window.</span>
<span class="sd">    :param stride: stride of the window. If not provided, its value is set to kernel_size.</span>
<span class="sd">        Default: None</span>
<span class="sd">    :param padding: implicit zero padding added on both sides. Default: 0</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="n">window_h</span><span class="p">,</span> <span class="n">window_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">padding_h</span><span class="p">,</span> <span class="n">padding_w</span> <span class="o">=</span> <span class="n">_pair</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Pooling</span><span class="p">(</span>
        <span class="n">window_h</span><span class="o">=</span><span class="n">window_h</span><span class="p">,</span>
        <span class="n">window_w</span><span class="o">=</span><span class="n">window_w</span><span class="p">,</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">padding_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">padding_w</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;MAX&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="avg_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.avg_pool2d.html#megengine.functional.avg_pool2d">[文档]</a><span class="k">def</span> <span class="nf">avg_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;AVERAGE_COUNT_EXCLUDE_PADDING&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies 2D average pooling over an input tensor.</span>

<span class="sd">    Refer to :class:`~.AvgPool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param kernel_size: size of the window.</span>
<span class="sd">    :param stride: stride of the window. If not provided, its value is set to ``kernel_size``.</span>
<span class="sd">        Default: None</span>
<span class="sd">    :param padding: implicit zero padding added on both sides. Default: 0</span>
<span class="sd">    :param mode: whether to count padding values. Default: &quot;AVERAGE_COUNT_EXCLUDE_PADDING&quot;</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="n">window_h</span><span class="p">,</span> <span class="n">window_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">padding_h</span><span class="p">,</span> <span class="n">padding_w</span> <span class="o">=</span> <span class="n">_pair</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Pooling</span><span class="p">(</span>
        <span class="n">window_h</span><span class="o">=</span><span class="n">window_h</span><span class="p">,</span>
        <span class="n">window_w</span><span class="o">=</span><span class="n">window_w</span><span class="p">,</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">padding_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">padding_w</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="adaptive_max_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.adaptive_max_pool2d.html#megengine.functional.adaptive_max_pool2d">[文档]</a><span class="k">def</span> <span class="nf">adaptive_max_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">oshp</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D max adaptive pooling over an input.</span>

<span class="sd">    Refer to :class:`~.MaxAdaptivePool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param oshp: `(OH, OW)` size of the output shape.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">oshp</span> <span class="o">=</span> <span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">AdaptivePooling</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;MAX&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,)</span>
    <span class="n">oshp</span> <span class="o">=</span> <span class="n">astensor1d</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="adaptive_avg_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.adaptive_avg_pool2d.html#megengine.functional.adaptive_avg_pool2d">[文档]</a><span class="k">def</span> <span class="nf">adaptive_avg_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">oshp</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D average adaptive pooling over an input.</span>

<span class="sd">    Refer to :class:`~.AvgAdaptivePool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param oshp: `(OH, OW)` size of the output shape.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">oshp</span> <span class="o">=</span> <span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">AdaptivePooling</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;AVERAGE&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,)</span>
    <span class="n">oshp</span> <span class="o">=</span> <span class="n">astensor1d</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="deformable_psroi_pooling"><a class="viewcode-back" href="../../../reference/api/megengine.functional.deformable_psroi_pooling.html#megengine.functional.deformable_psroi_pooling">[文档]</a><span class="k">def</span> <span class="nf">deformable_psroi_pooling</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">rois</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">trans</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">no_trans</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">part_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pooled_h</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pooled_w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">sample_per_part</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">spatial_scale</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">trans_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deformable PSROI(Position Sensitive Region of Interest) Pooling.</span>

<span class="sd">    :param inp: input feature map.</span>
<span class="sd">    :param rois: the rois for feature pooling.</span>
<span class="sd">    :param trans: input offset to psroi_pooling.</span>
<span class="sd">    :param no_trans: check the phase of DeformablePSROIPooling. False to the</span>
<span class="sd">                        1st phase, True to the 2nd phase.</span>
<span class="sd">    :param part_size: part size.</span>
<span class="sd">    :param sample_per_part: sample points of each part.</span>
<span class="sd">    :param pooled_shape: kernel shape of convolution.</span>
<span class="sd">    :param spatial_scale: the spatial_scale w.r.t input image.</span>
<span class="sd">    :param trans_std: multiplier used in 2nd phase.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">DeformablePSROIPooling</span><span class="p">(</span>
        <span class="n">no_trans</span><span class="o">=</span><span class="n">no_trans</span><span class="p">,</span>
        <span class="n">part_size</span><span class="o">=</span><span class="n">part_size</span><span class="p">,</span>
        <span class="n">pooled_h</span><span class="o">=</span><span class="n">pooled_h</span><span class="p">,</span>
        <span class="n">pooled_w</span><span class="o">=</span><span class="n">pooled_w</span><span class="p">,</span>
        <span class="n">sample_per_part</span><span class="o">=</span><span class="n">sample_per_part</span><span class="p">,</span>
        <span class="n">spatial_scale</span><span class="o">=</span><span class="n">spatial_scale</span><span class="p">,</span>
        <span class="n">trans_std</span><span class="o">=</span><span class="n">trans_std</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">rois</span><span class="p">,</span> <span class="n">trans</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="prelu"><a class="viewcode-back" href="../../../reference/api/megengine.functional.prelu.html#megengine.functional.prelu">[文档]</a><span class="k">def</span> <span class="nf">prelu</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise PReLU function.</span>

<span class="sd">    Refer to :class:`~.PReLU` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">maximum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">minimum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise leaky_relu function</span>

<span class="sd">    Refer to :class:`~.LeakyReLU` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">maximum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">negative_slope</span> <span class="o">*</span> <span class="n">minimum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>


<div class="viewcode-block" id="softplus"><a class="viewcode-back" href="../../../reference/api/megengine.functional.softplus.html#megengine.functional.softplus">[文档]</a><span class="k">def</span> <span class="nf">softplus</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise function:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{softplus}(x) = \log(1 + \exp(x))</span>

<span class="sd">    softplus is a smooth approximation to the ReLU function and can be used</span>
<span class="sd">    to constrain the output to be always positive.</span>
<span class="sd">    For numerical stability the implementation follows this transformation:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{softplus}(x) = \log(1 + \exp(x))</span>
<span class="sd">                           = \log(1 + \exp(-\text{abs}(x))) + \max(x, 0)</span>
<span class="sd">                           = \log1p(\exp(-\text{abs}(x))) + \text{relu}(x)</span>

<span class="sd">    :param inp: input tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-3, 3, dtype=np.float32))</span>
<span class="sd">        y = F.softplus(x)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [0.0486 0.1269 0.3133 0.6931 1.3133 2.1269]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">log1p</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">inp</span><span class="p">)))</span> <span class="o">+</span> <span class="n">relu</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span></div>


<div class="viewcode-block" id="logsoftmax"><a class="viewcode-back" href="../../../reference/api/megengine.functional.logsoftmax.html#megengine.functional.logsoftmax">[文档]</a><span class="k">def</span> <span class="nf">logsoftmax</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the :math:`\log(\text{softmax}(x))` function to an n-dimensional</span>
<span class="sd">    input tensor. The :math:`\text{logsoftmax}(x)` formulation can be simplified as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{logsoftmax}(x_{i}) = \log(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} )</span>

<span class="sd">    For numerical stability the implementation follows this transformation:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{logsoftmax}(x)</span>
<span class="sd">        = \log (\frac{\exp (x)}{\sum_{i}(\exp (x_{i}))})</span>
<span class="sd">        = x - \log (\sum_{i}(\exp (x_{i})))</span>
<span class="sd">        = x - \text{logsumexp}(x)</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param axis: axis along which :math:`\text{logsoftmax}(x)` will be applied.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32)).reshape(2,5)</span>
<span class="sd">        y = F.logsoftmax(x, axis=1)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[-4.4519 -3.4519 -2.4519 -1.4519 -0.4519]</span>
<span class="sd">         [-4.4519 -3.4519 -2.4519 -1.4519 -0.4519]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">inp</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="logsigmoid"><a class="viewcode-back" href="../../../reference/api/megengine.functional.logsigmoid.html#megengine.functional.logsigmoid">[文档]</a><span class="k">def</span> <span class="nf">logsigmoid</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise function:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{logsigmoid}(x) = \log(\frac{ 1 }{ 1 + \exp(-x)})</span>
<span class="sd">        = \log(1/(1 + \exp(-x)))</span>
<span class="sd">        = - \log(1 + \exp(-x))</span>
<span class="sd">        = - \text{softplus}(-x)</span>

<span class="sd">    :param inp: input tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32))</span>
<span class="sd">        y = F.logsigmoid(x)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [-5.0067 -4.0182 -3.0486 -2.1269 -1.3133 -0.6931 -0.3133 -0.1269 -0.0486</span>
<span class="sd">         -0.0181]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">softplus</span><span class="p">(</span><span class="o">-</span><span class="n">inp</span><span class="p">)</span></div>


<div class="viewcode-block" id="logsumexp"><a class="viewcode-back" href="../../../reference/api/megengine.functional.logsumexp.html#megengine.functional.logsumexp">[文档]</a><span class="k">def</span> <span class="nf">logsumexp</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="n">keepdims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the logarithm of the inputs&#39; exponential sum along the given :attr:`axis`.</span>

<span class="sd">    .. math::</span>

<span class="sd">        \text{logsumexp}(x)= \log \sum_{j=1}^{n} \exp \left(x_{j}\right)</span>

<span class="sd">    For numerical stability, the implementation follows this transformation:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \text{logsumexp}(x)= \log \sum_{j=1}^{n} \exp \left(x_{j}\right)</span>
<span class="sd">        = \text{logsumexp}(x)=b+\log \sum_{j=1}^{n} \exp \left(x_{j}-b\right)</span>

<span class="sd">    where</span>

<span class="sd">    .. math::</span>
<span class="sd">        b = \max(x_j)</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param axis: axis over which the sum is taken. It could be single axis or list of axes.</span>
<span class="sd">    :param keepdims: whether to retain :attr:`axis` or not for the output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32)).reshape(2,5)</span>
<span class="sd">        y = F.logsumexp(x, axis=1, keepdims=False)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [-0.5481  4.4519]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_value</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">keepdims</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">max_value</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">inp</span> <span class="o">-</span> <span class="n">max_value</span><span class="p">),</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">max_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span>
            <span class="nb">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">inp</span> <span class="o">-</span> <span class="n">max_value</span><span class="p">),</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span>
        <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_softmax_axis</span><span class="p">(</span><span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="mi">1</span>


<div class="viewcode-block" id="softmax"><a class="viewcode-back" href="../../../reference/api/megengine.functional.softmax.html#megengine.functional.softmax">[文档]</a><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a :math:`\text{softmax}(x)` function. :math:`\text{softmax}(x)` is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">            \text{softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}</span>

<span class="sd">    It is applied to all elements along axis, and rescales elements so that</span>
<span class="sd">    they stay in the range `[0, 1]` and sum to 1.</span>

<span class="sd">    See :class:`~megengine.module.activation.Softmax` for more details.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param axis: an axis along which :math:`\text{softmax}(x)` will be applied. By default,</span>
<span class="sd">        :math:`\text{softmax}(x)` will apply along the highest ranked axis.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32)).reshape(2,5)</span>
<span class="sd">        out = F.softmax(x)</span>
<span class="sd">        print(out.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[0.0117 0.0317 0.0861 0.2341 0.6364]</span>
<span class="sd">         [0.0117 0.0317 0.0861 0.2341 0.6364]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="n">_get_softmax_axis</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">cached</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">inp</span> <span class="o">-</span> <span class="n">offset</span><span class="p">)</span>
    <span class="n">down</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cached</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cached</span> <span class="o">/</span> <span class="n">down</span></div>


<div class="viewcode-block" id="batch_norm"><a class="viewcode-back" href="../../../reference/api/megengine.functional.batch_norm.html#megengine.functional.batch_norm">[文档]</a><span class="k">def</span> <span class="nf">batch_norm</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">running_mean</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">running_var</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies batch normalization to the input.</span>

<span class="sd">    Refer to :class:`~.BatchNorm2d` and :class:`~.BatchNorm1d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param running_mean: tensor to store running mean.</span>
<span class="sd">    :param running_var: tensor to store running variance.</span>
<span class="sd">    :param weight: scaling tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\gamma` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param bias: bias tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\beta` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param training: a boolean value to indicate whether batch norm is performed</span>
<span class="sd">        in training mode. Default: False</span>
<span class="sd">    :param momentum: value used for the ``running_mean`` and ``running_var``</span>
<span class="sd">        computation.</span>
<span class="sd">        Default: 0.9</span>
<span class="sd">    :param eps: a value added to the denominator for numerical stability.</span>
<span class="sd">        Default: 1e-5</span>
<span class="sd">    :param inplace: whether to update ``running_mean`` and ``running_var`` inplace or return new tensors</span>
<span class="sd">        Default: True</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;batch_norm for ndim != 4&quot;</span><span class="p">)</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">make_full_if_none</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">Const</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)()</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">astensor1d</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">builtin</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(),</span> <span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">astensor1d</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="n">has_mean</span> <span class="o">=</span> <span class="n">running_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">has_var</span> <span class="o">=</span> <span class="n">running_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">has_mean</span><span class="p">,</span> <span class="s2">&quot;running_mean must be provided in inference mode&quot;</span>
        <span class="k">assert</span> <span class="n">has_var</span><span class="p">,</span> <span class="s2">&quot;running_var must be provided in inference mode&quot;</span>

    <span class="k">if</span> <span class="n">has_mean</span> <span class="ow">and</span> <span class="n">running_mean</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>
    <span class="k">if</span> <span class="n">has_var</span> <span class="ow">and</span> <span class="n">running_var</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span>
    <span class="p">)</span>

    <span class="n">weight</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span>
            <span class="n">fwd_mode</span><span class="o">=</span><span class="n">BatchNorm</span><span class="o">.</span><span class="n">FwdMode</span><span class="o">.</span><span class="n">INFERENCE</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">param_dim</span><span class="o">=</span><span class="s2">&quot;DIM_1C11&quot;</span>
        <span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span>
            <span class="n">avg_factor</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">param_dim</span><span class="o">=</span><span class="s2">&quot;DIM_1C11&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">has_mean</span> <span class="ow">or</span> <span class="n">has_var</span><span class="p">:</span>
            <span class="n">running_mean</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">running_mean</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">running_var</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">running_var</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_mean</span><span class="p">,</span> <span class="n">new_var</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">inp</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                <span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_mean</span><span class="p">:</span>
                <span class="n">new_mean</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_var</span><span class="p">:</span>
                <span class="n">new_var</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">has_mean</span><span class="p">:</span>
                    <span class="n">running_mean</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_mean</span>
                <span class="k">if</span> <span class="n">has_var</span><span class="p">:</span>
                    <span class="n">running_var</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_var</span>

                <span class="k">return</span> <span class="n">inp</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">new_mean</span><span class="p">,</span> <span class="n">new_var</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">inp</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">inp</span></div>


<div class="viewcode-block" id="sync_batch_norm"><a class="viewcode-back" href="../../../reference/api/megengine.functional.sync_batch_norm.html#megengine.functional.sync_batch_norm">[文档]</a><span class="k">def</span> <span class="nf">sync_batch_norm</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">running_mean</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">running_var</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">momentum</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">eps_mode</span><span class="o">=</span><span class="s2">&quot;ADDITIVE&quot;</span><span class="p">,</span>
    <span class="n">group</span><span class="o">=</span><span class="n">WORLD</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies synchronized batch normalization to the input.</span>

<span class="sd">    Refer to :class:`~.BatchNorm2d` and :class:`~.BatchNorm1d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param running_mean: tensor to store running mean.</span>
<span class="sd">    :param running_var: tensor to store running variance.</span>
<span class="sd">    :param weight: scaling tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\gamma` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param bias: bias tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\beta` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param training: a boolean value to indicate whether batch norm is performed</span>
<span class="sd">        in traning mode. Default: False</span>
<span class="sd">    :param momentum: value used for the ``running_mean`` and ``running_var``</span>
<span class="sd">        computation.</span>
<span class="sd">        Default: 0.9</span>
<span class="sd">    :param eps: a value added to the denominator for numerical stability.</span>
<span class="sd">        Default: 1e-5</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">eps_mode</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;MAX&quot;</span><span class="p">,</span> <span class="s2">&quot;ADDITIVE&quot;</span><span class="p">},</span> <span class="s2">&quot;unknown eps_mode: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">eps_mode</span><span class="p">)</span>
    <span class="n">_channels</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">_ndim</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">_device</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">device</span>
    <span class="n">_dtype</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">_param_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">_channels</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">_ndim</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">_reduce_axis</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">_ndim</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">_sum_on_channel</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">inp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">_reduce_axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">_ndim</span><span class="p">):</span>
            <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">reduce_size</span> <span class="o">*</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">channel_x1s</span> <span class="o">=</span> <span class="n">_sum_on_channel</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
        <span class="n">channel_x2s</span> <span class="o">=</span> <span class="n">_sum_on_channel</span><span class="p">(</span><span class="n">inp</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_distributed</span><span class="p">():</span>
            <span class="c1"># reduce all nodes&#39; data to calculate mean and variance</span>
            <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">Tensor</span><span class="p">(</span><span class="n">reduce_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">_dtype</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">_ndim</span>
            <span class="p">)</span>
            <span class="n">stat</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">reduce_size</span><span class="p">,</span> <span class="n">channel_x1s</span><span class="p">,</span> <span class="n">channel_x2s</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">stat</span> <span class="o">=</span> <span class="n">all_reduce_sum</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">group</span><span class="p">)</span>
            <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">stat</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">channel_x1s</span> <span class="o">=</span> <span class="n">stat</span><span class="p">[:,</span> <span class="mi">1</span> <span class="p">:</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">_channels</span><span class="p">]</span>
            <span class="n">channel_x2s</span> <span class="o">=</span> <span class="n">stat</span><span class="p">[:,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">_channels</span> <span class="p">:]</span>

        <span class="n">channel_mean</span> <span class="o">=</span> <span class="n">channel_x1s</span> <span class="o">/</span> <span class="n">reduce_size</span>
        <span class="n">channel_variance</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">channel_x1s</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="o">-</span><span class="n">reduce_size</span> <span class="o">*</span> <span class="n">reduce_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">channel_x2s</span> <span class="o">/</span> <span class="n">reduce_size</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">running_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">running_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">channel_variance</span> <span class="o">=</span> <span class="n">running_var</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>
        <span class="n">channel_mean</span> <span class="o">=</span> <span class="n">running_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>

    <span class="n">invsqrt_channel_variance</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">maximum</span><span class="p">(</span><span class="n">channel_variance</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span> <span class="k">if</span> <span class="n">eps_mode</span> <span class="o">==</span> <span class="s2">&quot;MAX&quot;</span> <span class="k">else</span> <span class="n">channel_variance</span> <span class="o">+</span> <span class="n">eps</span>
    <span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>

    <span class="c1"># outvar = output * weight + bias</span>
    <span class="c1"># where output = inp * invsqrt_channel_variance + (</span>
    <span class="c1">#    -channel_mean * invsqrt_channel_variance</span>
    <span class="c1"># )</span>
    <span class="c1"># Manually expand output for gopt</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">inv_var_wt</span> <span class="o">=</span> <span class="n">invsqrt_channel_variance</span> <span class="o">*</span> <span class="n">weight</span>
        <span class="n">neg_channel_mean</span> <span class="o">=</span> <span class="o">-</span><span class="n">channel_mean</span>
        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outvar</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">inv_var_wt</span> <span class="o">+</span> <span class="p">(</span><span class="n">neg_channel_mean</span> <span class="o">*</span> <span class="n">inv_var_wt</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outvar</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">inv_var_wt</span> <span class="o">+</span> <span class="n">neg_channel_mean</span> <span class="o">*</span> <span class="n">inv_var_wt</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outvar</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">invsqrt_channel_variance</span> <span class="o">+</span> <span class="p">(</span>
            <span class="o">-</span><span class="n">channel_mean</span> <span class="o">*</span> <span class="n">invsqrt_channel_variance</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outvar</span> <span class="o">=</span> <span class="n">outvar</span> <span class="o">+</span> <span class="n">bias</span>

    <span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="n">running_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">running_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">running_mean</span> <span class="o">*=</span> <span class="n">momentum</span>
        <span class="n">running_mean</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">channel_mean</span>
        <span class="n">channel_variance_unbiased</span> <span class="o">=</span> <span class="n">channel_x1s</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span>
            <span class="o">-</span><span class="n">reduce_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">reduce_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">+</span> <span class="n">channel_x2s</span> <span class="o">/</span> <span class="p">(</span><span class="n">reduce_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">running_var</span> <span class="o">*=</span> <span class="n">momentum</span>
        <span class="n">running_var</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">channel_variance_unbiased</span>

    <span class="k">return</span> <span class="n">outvar</span></div>


<div class="viewcode-block" id="one_hot"><a class="viewcode-back" href="../../../reference/api/megengine.functional.one_hot.html#megengine.functional.one_hot">[文档]</a><span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs one-hot encoding for the input tensor.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param num_classes: number of classes denotes the last dimension of the output tensor.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(1, 4, dtype=np.int32))</span>
<span class="sd">        out = F.one_hot(x, num_classes=4)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[0 1 0 0]</span>
<span class="sd">         [0 0 1 0]</span>
<span class="sd">         [0 0 0 1]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">zeros_tensor</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_classes</span><span class="p">],</span> <span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">ones_tensor</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">IndexingSetOneHot</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">zeros_tensor</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">ones_tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span>
    <span class="n">inp1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">inp2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a matrix multiplication of the matrices ``inp1`` and ``inp2``.</span>

<span class="sd">    With different inputs dim, this function behaves differently:</span>

<span class="sd">    - Both 1-D tensor, simply forward to ``dot``.</span>
<span class="sd">    - Both 2-D tensor, normal matrix multiplication.</span>
<span class="sd">    - If one input tensor is 1-D, matrix vector multiplication.</span>
<span class="sd">    - If at least one tensor are 3-dimensional or &gt;3-dimensional, the other tensor should have dim &gt;= 2, the batched matrix-matrix is returned, and the tensor with smaller dimension will</span>
<span class="sd">      be broadcasted. For example:</span>
<span class="sd">        - inp1: `(n, k, m)`, inp2: `(n, m, p)`, return: `(n, k, p)`</span>
<span class="sd">        - inp1: `(n, k, m)`, inp2: `(m, p)`, return: `(n, k, p)`</span>
<span class="sd">        - inp1: `(n, j, k, m)`, inp2: `(n, j, m, p)`, return: `(n, j, k, p)`</span>

<span class="sd">    :param inp1: first matrix to be multiplied.</span>
<span class="sd">    :param inp2: second matrix to be multiplied.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        data1 = tensor(np.arange(0, 6, dtype=np.float32).reshape(2, 3))</span>
<span class="sd">        data2 = tensor(np.arange(0, 6, dtype=np.float32).reshape(3, 2))</span>
<span class="sd">        out = F.matmul(data1, data2)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[10. 13.]</span>
<span class="sd">         [28. 40.]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">remove_row</span><span class="p">,</span> <span class="n">remove_col</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span>
    <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>

    <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">inp2</span><span class="o">.</span><span class="n">ndim</span>
    <span class="c1"># handle dim=1 cases, dot and matrix-vector multiplication</span>
    <span class="k">if</span> <span class="n">dim1</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">dim2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="c1"># the underlying matmul op requires input dims to be at least 2</span>
    <span class="k">if</span> <span class="n">dim1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">inp1</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">dim1</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">remove_row</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">dim2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">inp2</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">dim2</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">remove_col</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">batch_shape</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">shape2</span> <span class="o">=</span> <span class="n">inp2</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">maxdim</span> <span class="o">=</span> <span class="n">dim1</span> <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;</span> <span class="n">dim2</span> <span class="k">else</span> <span class="n">dim2</span>
    <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;=</span> <span class="mi">3</span> <span class="ow">or</span> <span class="n">dim2</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_symbolic_shape</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape2</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="n">inp2</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp2</span><span class="p">,</span> <span class="n">shape2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&lt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape1</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">shape2</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="n">inp1</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">shape1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">maxdim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="c1"># compress inputs to 3d</span>
                <span class="p">(</span><span class="n">inp1</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                    <span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">inp1</span><span class="p">,</span> <span class="n">concat</span><span class="p">([</span><span class="n">prod</span><span class="p">(</span><span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">inp2</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                    <span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">inp2</span><span class="p">,</span> <span class="n">concat</span><span class="p">([</span><span class="n">prod</span><span class="p">(</span><span class="n">shape2</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape2</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
                <span class="n">inp2</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp2</span><span class="p">,</span> <span class="n">shape2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&lt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape1</span> <span class="o">=</span> <span class="n">shape2</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
                <span class="n">inp1</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">shape1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">maxdim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="c1"># compress inputs to 3d</span>
                <span class="n">inp1</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
                <span class="n">inp2</span> <span class="o">=</span> <span class="n">inp2</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">BatchedMatrixMul</span><span class="p">(</span>
            <span class="n">transposeA</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span>
            <span class="n">transposeB</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
            <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">MatrixMul</span><span class="p">(</span>
            <span class="n">transposeA</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span>
            <span class="n">transposeB</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
            <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maxdim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_symbolic_shape</span><span class="p">():</span>
            <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                <span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">result</span><span class="p">,</span> <span class="n">concat</span><span class="p">([</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
    <span class="k">if</span> <span class="n">remove_row</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">remove_col</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">dot</span><span class="p">(</span><span class="n">inp1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">inp2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes dot-product of two vectors ``inp1`` and ``inp2``.</span>
<span class="sd">    inputs must be 1-dimensional or scalar. A scalar input is automatically broadcasted.</span>
<span class="sd">    Refer to :func:`~.matmul` for more general usage.</span>

<span class="sd">    :param inp1: first vector.</span>
<span class="sd">    :param inp2: second vector.</span>
<span class="sd">    :return: output value.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        data1 = tensor(np.arange(0, 6, dtype=np.float32))</span>
<span class="sd">        data2 = tensor(np.arange(0, 6, dtype=np.float32))</span>
<span class="sd">        out = F.dot(data1, data2)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        55.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Dot</span><span class="p">()</span>
    <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">inp1</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">inp2</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;=</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="s2">&quot;Input tensors for dot must be 1-dimensional or scalar&quot;</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="n">setscalar</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">dropout</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor where each of the elements are randomly set to zero</span>
<span class="sd">    with probability P = ``drop_prob``. Optionally rescale the output tensor if ``training`` is True.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param drop_prob: probability to drop (set to zero) a single element.</span>
<span class="sd">    :param training: the default behavior of ``dropout`` during training is to rescale the output,</span>
<span class="sd">        then it can be replaced by an :class:`~.Identity` during inference. Default: True</span>
<span class="sd">    :return: the output tensor</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.ones(10, dtype=np.float32))</span>
<span class="sd">        out = F.dropout(x, 1./3.)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>
<span class="sd">        :options: +SKIP</span>

<span class="sd">        [1.5 1.5 0.  1.5 1.5 1.5 1.5 1.5 1.5 1.5]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">drop_prob</span> <span class="o">&lt;</span> <span class="mi">1</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">rv</span> <span class="o">&gt;</span> <span class="n">drop_prob</span>
    <span class="n">inp</span> <span class="o">*=</span> <span class="n">mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
        <span class="n">inp</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">drop_prob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inp</span>


<span class="k">def</span> <span class="nf">embedding</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">norm_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies lookup table for embedding.</span>

<span class="sd">    :param inp: tensor with indices.</span>
<span class="sd">    :param weight: learnable weights which embeds from.</span>
<span class="sd">    :param padding_idx: should be set to None, not supported now.</span>
<span class="sd">    :param max_norm: should be set to None, not supported now.</span>
<span class="sd">    :param norm_type: should be set to None, not supported now.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Refer to :class:`~.Embedding` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">padding_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not support padding_idx Now!&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">norm_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not support weight normlization Now!&quot;</span><span class="p">)</span>

    <span class="n">dest_shp</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">weight</span><span class="p">[</span><span class="n">inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dest_shp</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">indexing_one_hot</span><span class="p">(</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One-hot indexing for some axes.</span>

<span class="sd">    :param src: input tensor.</span>
<span class="sd">    :param index: index tensor.</span>
<span class="sd">    :param axis: axis on src for which values in index index. Default: 1</span>
<span class="sd">    :param keepdims: whether not to remove the axis in result. Default: False</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import megengine.functional as F</span>
<span class="sd">        from megengine import tensor</span>

<span class="sd">        src = tensor([[1.0, 2.0]])</span>
<span class="sd">        index = tensor([0])</span>
<span class="sd">        val = F.indexing_one_hot(src, index)</span>
<span class="sd">        print(val.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [1.]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">),</span> <span class="s2">&quot;src must be of Tensor type&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">IndexingOneHot</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_single_value</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">keepdims</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="conv1d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.conv1d.html#megengine.functional.conv1d">[文档]</a><span class="k">def</span> <span class="nf">conv1d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;1D convolution operation.</span>

<span class="sd">    Refer to :class:`~.Conv1d` for more information.</span>

<span class="sd">    :param inp: The feature map of the convolution operation</span>
<span class="sd">    :param weight: The convolution kernel</span>
<span class="sd">    :param bias: The bias added to the result of convolution (if given)</span>
<span class="sd">    :param stride: Stride of the 1D convolution operation. Default: 1</span>
<span class="sd">    :param padding: Size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: Dilation of the 1D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups to divide input and output channels into,</span>
<span class="sd">        so as to perform a &quot;grouped convolution&quot;. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by ``groups``,</span>
<span class="sd">        and the shape of weight should be ``(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)``.</span>
<span class="sd">    :type conv_mode: string or :class:`mgb.opr_param_defs.Convolution.Mode`</span>
<span class="sd">    :param conv_mode: Supports &#39;CROSS_CORRELATION&#39;. Default:</span>
<span class="sd">        &#39;CROSS_CORRELATION&#39;.</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`mgb.opr_param_defs.Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: When set to &#39;DEFAULT&#39;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &#39;FLOAT32&#39;,</span>
<span class="sd">        Float32 would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>
    <span class="k">assert</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;the input dimension of conv1d should be 3&quot;</span>
    <span class="k">assert</span> <span class="n">weight</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;the weight dimension of conv1d should be 3&quot;</span>

    <span class="n">inp</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">bias</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;the bias dimension of conv1d should be 3&quot;</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="n">stride_h</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="n">pad_h</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="n">dilate_h</span> <span class="o">=</span> <span class="n">dilation</span>

    <span class="n">sparse_type</span> <span class="o">=</span> <span class="s2">&quot;DENSE&quot;</span> <span class="k">if</span> <span class="n">groups</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;GROUP&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Convolution</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_execution_strategy</span><span class="p">(),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="n">sparse_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<span class="k">def</span> <span class="nf">nvof</span><span class="p">(</span><span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements NVIDIA Optical Flow SDK.</span>

<span class="sd">    :src shape: input tensor with shape (n, t, h, w, c4).</span>
<span class="sd">    :src dtype: uint8.</span>
<span class="sd">    :param precision: 0:NV_OF_PERF_LEVEL_SLOW 1:NV_OF_PERF_LEVEL_MEDIUM 2:NV_OF_PERF_LEVEL_FAST.</span>
<span class="sd">    :output shape: (n, t-1, h//4, w//4, c2).</span>
<span class="sd">    :output dtype: int16.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = np.random.random_integers(0, 255, (1,2,224,244,4)).astype(&quot;uint8&quot;)</span>
<span class="sd">        src = tensor(x)</span>
<span class="sd">        result = F.nn.nvof(src, precision=1)</span>
<span class="sd">        print(result.numpy())</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">src</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">5</span> <span class="ow">and</span> <span class="n">src</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>

    <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">NvOf</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">src</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">hswish</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise `x * relu6(x + 3) / 6`.</span>

<span class="sd">    :param x: input tensor.</span>
<span class="sd">    :return: computed tensor.</span>

<span class="sd">    Example:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(5).astype(np.float32))</span>
<span class="sd">        out = F.hswish(x)</span>
<span class="sd">        print(out.numpy().round(decimals=4))</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [0.     0.6667 1.6667 3.     4.    ]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_elwise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">Elemwise</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">H_SWISH</span><span class="p">)</span>


<div class="viewcode-block" id="sigmoid"><a class="viewcode-back" href="../../../reference/api/megengine.functional.sigmoid.html#megengine.functional.sigmoid">[文档]</a><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Element-wise `1 / ( 1 + exp( -x ) )`.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_elwise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">Elemwise</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">SIGMOID</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">hsigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Element-wise `relu6(x + 3) / 6`.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">relu6</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="mi">6</span>


<div class="viewcode-block" id="relu"><a class="viewcode-back" href="../../../reference/api/megengine.functional.relu.html#megengine.functional.relu">[文档]</a><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Element-wise `max(x, 0)`.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_elwise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">Elemwise</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">RELU</span><span class="p">)</span></div>


<div class="viewcode-block" id="relu6"><a class="viewcode-back" href="../../../reference/api/megengine.functional.relu6.html#megengine.functional.relu6">[文档]</a><span class="k">def</span> <span class="nf">relu6</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Element-wise `min(max(x, 0), 6)`.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">minimum</span><span class="p">(</span><span class="n">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">6</span><span class="p">)</span></div>


<span class="n">interpolate</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;interpolate&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">roi_pooling</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;roi_pooling&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">roi_align</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;roi_align&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">nms</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;nms&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">resize</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;resize&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">remap</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;remap&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">warp_affine</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span><span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;warp_affine&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">warp_perspective</span> <span class="o">=</span> <span class="n">deprecated_func</span><span class="p">(</span>
    <span class="s2">&quot;1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;megengine.functional.vision&quot;</span><span class="p">,</span> <span class="s2">&quot;warp_perspective&quot;</span><span class="p">,</span> <span class="kc">True</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">.loss</span> <span class="kn">import</span> <span class="o">*</span>  <span class="c1"># isort:skip</span>
<span class="kn">from</span> <span class="nn">.quantized</span> <span class="kn">import</span> <span class="n">conv_bias_activation</span>  <span class="c1"># isort:skip</span>
</pre></div>

              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.3c6125c0ae68274ddd1b.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020-2021, The MegEngine Open Source Team.<br/>
        由 <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3 创建。<br/>
    </p>
  </div>
</footer>
  </body>
</html>