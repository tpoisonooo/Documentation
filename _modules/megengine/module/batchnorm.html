
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>megengine.module.batchnorm &#8212; MegEngine 1.3.0 文档</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.93dda2a1e4f2b831d8345b5b3dbee4ea.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3c6125c0ae68274ddd1b.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
      
      <a class="navbar-brand" href="../../../index.html">
        <img src="../../../_static/logo.png" class="logo" alt="logo">
      </a>
      
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../getting-started/index.html">
  新手入门
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../user-guide/index.html">
  用户指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../reference/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../development/index.html">
  开发者指南
 </a>
</li>

        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discuss.megengine.org.cn/">论坛<i class="fas fa-external-link-alt"></i></a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://megengine.org.cn/">官网<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>

      <form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="输入搜索文本..." aria-label="输入搜索文本..." autocomplete="off" >
</form>
      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/MegEngine/MegEngine" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>

      <script type="text/javascript">
  (function () {
    window.versionSwitcher = {
      pageName: "_modules/megengine/module/batchnorm.html",
      versionJsonUrl: "/doc/version.json",
      enableLocaleSupport: "True" === "True",
      // TODO read from "zh, en"
      allLocales: [
        {
          "locale": "zh",
          "display": "中文"
        },
        {
          "locale": "en",
          "display": "EN"
        }
      ]
    }
  })();
</script>

<ul class="navbar-nav">
  <li class="nav-item dropdown">
    <button id="version-dropdown" class="btn btn-secondary btn-sm dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      <!-- placeholder for javascript filling above -->
    </button>
    <div id="version-menu" class="dropdown-menu" style="min-width: 6rem;">
      <!-- placeholder for javascript filling above -->
    </div>
  </li>
  <li class="nav-item">
    <span id="locale-switcher">
      <!-- placeholder for locale switcher -->
    </span>
  </li>
</ul>
      
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    
</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>megengine.module.batchnorm 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># MegEngine is Licensed under the Apache License, Version 2.0 (the &quot;License&quot;)</span>
<span class="c1">#</span>
<span class="c1"># Copyright (c) 2014-2021 Megvii Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an</span>
<span class="c1"># &quot;AS IS&quot; BASIS, WITHOUT ARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">..distributed.group</span> <span class="kn">import</span> <span class="n">WORLD</span><span class="p">,</span> <span class="n">Group</span>
<span class="kn">from</span> <span class="nn">..functional.nn</span> <span class="kn">import</span> <span class="n">batch_norm</span><span class="p">,</span> <span class="n">sync_batch_norm</span>
<span class="kn">from</span> <span class="nn">..tensor</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">from</span> <span class="nn">.module</span> <span class="kn">import</span> <span class="n">Module</span>


<span class="k">class</span> <span class="nc">_BatchNorm</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_features</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">freeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">affine</span> <span class="o">=</span> <span class="n">affine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span> <span class="o">=</span> <span class="n">track_running_stats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_track_running_stats_saved</span> <span class="o">=</span> <span class="n">track_running_stats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">freeze</span> <span class="o">=</span> <span class="n">freeze</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freeze</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_track_running_stats_saved</span>
            <span class="p">),</span> <span class="s2">&quot;track_running_stats must be initilized to True if freeze is True&quot;</span>
        <span class="n">tshape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">tshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">tshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">reset_running_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span>
            <span class="n">init</span><span class="o">.</span><span class="n">ones_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">running_var</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_running_stats</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">ones_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_input_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_input_ndim</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_track_running_stats_saved</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span> <span class="o">==</span> <span class="kc">False</span>
            <span class="p">),</span> <span class="s2">&quot;track_running_stats can not be initilized to False and changed to True later&quot;</span>

        <span class="n">inp_shape</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">_ndims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_ndims</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">origin_shape</span> <span class="o">=</span> <span class="n">inp_shape</span>
            <span class="k">if</span> <span class="n">_ndims</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">n</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">inp_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inp_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">_ndims</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">inp_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inp_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inp_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

        <span class="n">_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freeze</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_weight</span> <span class="o">=</span> <span class="n">_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_bias</span> <span class="o">=</span> <span class="n">_bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="c1"># Need to expand to elementwise operations here</span>
            <span class="c1"># see MGB_IMPL_OPR_GRAD(BatchNormForward) in src/opr/impl/dnn/batch_norm.cpp</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">scale</span> <span class="o">*=</span> <span class="n">_weight</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">*</span> <span class="n">scale</span>
            <span class="k">if</span> <span class="n">_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">bias</span> <span class="o">+=</span> <span class="n">_bias</span>
            <span class="k">return</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">bias</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># useless</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">batch_norm</span><span class="p">(</span>
            <span class="n">inp</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">_weight</span><span class="p">,</span>
            <span class="n">_bias</span><span class="p">,</span>
            <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span>
            <span class="ow">or</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="n">momentum</span><span class="o">=</span><span class="n">exponential_average_factor</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">_ndims</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">origin_shape</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">_module_info_string</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;</span><span class="si">{num_features}</span><span class="s2">, eps=</span><span class="si">{eps}</span><span class="s2">, momentum=</span><span class="si">{momentum}</span><span class="s2">, affine=</span><span class="si">{affine}</span><span class="s2">, &quot;</span>
            <span class="s2">&quot;track_running_stats=</span><span class="si">{track_running_stats}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>


<div class="viewcode-block" id="SyncBatchNorm"><a class="viewcode-back" href="../../../reference/api/megengine.module.SyncBatchNorm.html#megengine.module.SyncBatchNorm">[文档]</a><span class="k">class</span> <span class="nc">SyncBatchNorm</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies Synchronized Batch Normalization for distributed training.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_features</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">freeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Group</span><span class="p">]</span> <span class="o">=</span> <span class="n">WORLD</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">num_features</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">affine</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="p">,</span> <span class="n">freeze</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group</span> <span class="o">=</span> <span class="n">group</span>

    <span class="k">def</span> <span class="nf">_check_input_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;expected 2D, 3D or 4D input (got </span><span class="si">{}</span><span class="s2">D input)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_input_ndim</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

        <span class="n">inp_shape</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">_ndims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_ndims</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">new_shape</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">origin_shape</span> <span class="o">=</span> <span class="n">inp_shape</span>
            <span class="k">if</span> <span class="n">_ndims</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">origin_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">_ndims</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">new_shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">origin_shape</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;expected 2D, 3D or 4D input (got </span><span class="si">{}</span><span class="s2">D input)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp_shape</span><span class="p">))</span>
                <span class="p">)</span>

            <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># useless</span>

        <span class="n">_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freeze</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_weight</span> <span class="o">=</span> <span class="n">_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_bias</span> <span class="o">=</span> <span class="n">_bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">sync_batch_norm</span><span class="p">(</span>
            <span class="n">inp</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span><span class="p">,</span>
            <span class="n">_weight</span><span class="p">,</span>
            <span class="n">_bias</span><span class="p">,</span>
            <span class="n">training</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">freeze</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="n">momentum</span><span class="o">=</span><span class="n">exponential_average_factor</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">group</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">_ndims</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">origin_shape</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="BatchNorm1d"><a class="viewcode-back" href="../../../reference/api/megengine.module.BatchNorm1d.html#megengine.module.BatchNorm1d">[文档]</a><span class="k">class</span> <span class="nc">BatchNorm1d</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies Batch Normalization over a 2D/3D tensor.</span>

<span class="sd">    Refer to :class:`~.BatchNorm2d` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_check_input_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">}:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;expected 2D or 3D input (got </span><span class="si">{}</span><span class="s2">D input)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="BatchNorm2d"><a class="viewcode-back" href="../../../reference/api/megengine.module.BatchNorm2d.html#megengine.module.BatchNorm2d">[文档]</a><span class="k">class</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies Batch Normalization over a 4D tensor.</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta</span>

<span class="sd">    The mean and standard-deviation are calculated per-dimension over</span>
<span class="sd">    the mini-batches and :math:`\gamma` and :math:`\beta` are learnable</span>
<span class="sd">    parameter vectors.</span>

<span class="sd">    By default, during training this layer keeps running estimates of its</span>
<span class="sd">    computed mean and variance, which are then used for normalization during</span>
<span class="sd">    evaluation. The running estimates are kept with a default :attr:`momentum`</span>
<span class="sd">    of 0.9.</span>

<span class="sd">    If :attr:`track_running_stats` is set to ``False``, this layer will not</span>
<span class="sd">    keep running estimates, batch statistics is used during</span>
<span class="sd">    evaluation time instead.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This :attr:`momentum` argument is different from one used in optimizer</span>
<span class="sd">        classes and the conventional notion of momentum. Mathematically, the</span>
<span class="sd">        update rule for running statistics here is</span>
<span class="sd">        :math:`\hat{x}_\text{new} = \text{momentum} \times \hat{x} + (1 - \text{momentum}) \times x_t`,</span>
<span class="sd">        where :math:`\hat{x}` is the estimated statistic and :math:`x_t` is the</span>
<span class="sd">        new observed value.</span>

<span class="sd">    Because the Batch Normalization is done over the `C` dimension, computing</span>
<span class="sd">    statistics on `(N, H, W)` slices, it&#39;s common terminology to call this</span>
<span class="sd">    Spatial Batch Normalization.</span>

<span class="sd">    :type num_features: int</span>
<span class="sd">    :param num_features: usually :math:`C` from an input of shape</span>
<span class="sd">        :math:`(N, C, H, W)` or the highest ranked dimension of an input</span>
<span class="sd">        less than 4D.</span>
<span class="sd">    :type eps: float</span>
<span class="sd">    :param eps: a value added to the denominator for numerical stability.</span>
<span class="sd">        Default: 1e-5</span>
<span class="sd">    :type momentum: float</span>
<span class="sd">    :param momentum: the value used for the ``running_mean`` and ``running_var`` computation.</span>
<span class="sd">        Default: 0.9</span>
<span class="sd">    :type affine: bool</span>
<span class="sd">    :param affine: a boolean value that when set to True, this module has</span>
<span class="sd">        learnable affine parameters. Default: True</span>
<span class="sd">    :type track_running_stats: bool</span>
<span class="sd">    :param track_running_stats: when set to True, this module tracks the</span>
<span class="sd">        running mean and variance. When set to False, this module does not</span>
<span class="sd">        track such statistics and always uses batch statistics in both training</span>
<span class="sd">        and eval modes. Default: True</span>

<span class="sd">    :type freeze: bool</span>
<span class="sd">    :param freeze: when set to True, this module does not update the</span>
<span class="sd">        running mean and variance, and uses the running mean and variance instead of</span>
<span class="sd">        the batch mean and batch variance to normalize the input. The parameter takes effect</span>
<span class="sd">        only when the module is initilized with track_running_stats as True.</span>
<span class="sd">        Default: False</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        import megengine as mge</span>
<span class="sd">        import megengine.module as M</span>

<span class="sd">        # With Learnable Parameters</span>
<span class="sd">        m = M.BatchNorm2d(4)</span>
<span class="sd">        inp = mge.tensor(np.random.rand(1, 4, 3, 3).astype(&quot;float32&quot;))</span>
<span class="sd">        oup = m(inp)</span>
<span class="sd">        print(m.weight.numpy().flatten(), m.bias.numpy().flatten())</span>
<span class="sd">        # Without L`e`arnable Parameters</span>
<span class="sd">        m = M.BatchNorm2d(4, affine=False)</span>
<span class="sd">        oup = m(inp)</span>
<span class="sd">        print(m.weight, m.bias)</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [1. 1. 1. 1.] [0. 0. 0. 0.]</span>
<span class="sd">        None None</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_check_input_ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;expected 4D input (got </span><span class="si">{}</span><span class="s2">D input)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span></div>
</pre></div>

              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.3c6125c0ae68274ddd1b.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020-2021, The MegEngine Open Source Team.<br/>
        由 <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3 创建。<br/>
    </p>
  </div>
</footer>
  </body>
</html>